# ADR-003: AI Integration and Natural Language Processing Strategy

## Status
Accepted

## Context
We needed to implement an AI-powered chatbot that could understand natural language queries about professors and courses. The chatbot needed to:
- Extract professor names from user messages (with typo tolerance)
- Extract course codes and numbers from queries
- Understand context from previous messages (pronouns like "her", "his", "their")
- Filter data by semester when specified
- Provide intelligent analysis of grade distributions
- Handle follow-up questions without repeating context

Key challenges:
- Professor names in database may not match user input exactly
- Course codes can be written in various formats (CSCI 212, CS 212, 212)
- Natural language is ambiguous and context-dependent
- Need to balance AI capabilities with API costs
- Hackathon timeline required quick implementation

Key requirements:
- Accurate entity extraction (professors, courses, semesters)
- Context-aware conversation handling
- Intelligent responses based on grade distribution data
- Cost-effective API usage
- Fast response times

## Decision
We will use **OpenAI GPT-4 API** for AI-powered responses because:
1. Powerful natural language understanding
2. Can analyze grade distribution data and provide insights
3. Context-aware responses with conversation history
4. Pre-trained model - no training required
5. Good documentation and SDK support

We will use **regex-based pattern matching** for entity extraction because:
1. Fast and deterministic extraction
2. No API costs for simple extraction tasks
3. Can handle common patterns (professor names, course codes)
4. Easy to debug and iterate
5. Works offline

We will use **fuzzy matching (Levenshtein distance)** for professor name matching because:
1. Handles typos and variations in names
2. Can match "chyn" to "Chyn, D" or "chyns" to "Chyn"
3. Fast enough for real-time queries
4. Configurable similarity threshold
5. Cached results for performance

We will use **conversation context management** with session storage because:
1. Enables follow-up questions with pronouns
2. Remembers last professor/course/semester mentioned
3. Provides better user experience
4. Stored in SQLite for persistence
5. Session-based isolation

We will use **multi-level caching strategy** because:
1. Node-cache for in-memory caching of AI responses
2. Reduces OpenAI API calls and costs
3. Improves response times for repeated queries
4. Configurable TTL (30 minutes default)
5. Cache key based on query content

We will use **prompt engineering** to structure AI responses because:
1. Provides clear instructions to AI
2. Includes relevant grade distribution data in context
3. Ensures consistent response format
4. Reduces hallucination by grounding in data
5. Can be iteratively improved

## Consequences

### Positive
- Accurate entity extraction with regex patterns
- Fuzzy matching handles typos and name variations
- Context-aware conversations provide better UX
- Caching significantly reduces API costs
- Fast response times for cached queries
- AI provides intelligent analysis of grade data
- Prompt engineering ensures relevant responses

### Negative
- OpenAI API costs can add up with high usage
- Regex patterns may miss edge cases
- Fuzzy matching requires tuning similarity threshold
- Conversation context adds complexity
- Prompt engineering requires iteration
- API rate limits may affect performance
- Caching may serve stale responses

## Implementation Details

### Entity Extraction Pipeline
1. **Professor Name Extraction**: 
   - Check for possessive forms ("chyn's", "waxman's")
   - Pattern matching for "Professor X", "Prof. Y", "Dr. Z"
   - Fuzzy matching against database of all professor names
   - Handles comma-separated names ("Williams, C")

2. **Course Code Extraction**:
   - Patterns for "CSCI 212", "CS 212", "212 class"
   - Handles subject codes and course numbers separately
   - Validates against common course patterns

3. **Semester Extraction**:
   - Detects "Spring 2025", "SP25", "FA24", etc.
   - Converts to database format (SP25, FA24, SU25)
   - Filters grade data by semester when specified

### Conversation Context Management
- Stores last professor, course, and semester in session
- Enables follow-up questions: "What about her CSCI 212 class?"
- Handles pronouns: "her", "his", "their" refer to last mentioned professor
- Context persists across messages in same session
- Stored in SQLite conversations.db

### AI Prompt Structure
```
System: You are a helpful assistant for Queens College students.
User: [Grade distribution data + user query]
Instructions:
- Focus on specific professor/course
- Keep response concise
- Analyze grade patterns
- Provide practical insights
```

### Caching Strategy
- Cache key: `chat_${prompt.substring(0, 50)}`
- TTL: 30 minutes (1800 seconds)
- In-memory cache using Node-cache
- Cache hit rate significantly reduces API calls

## Migration Plan

### Day 1: Basic Extraction
- Implemented regex patterns for professor and course extraction
- Basic OpenAI API integration
- Simple prompt structure
- No caching initially

### Day 2: Advanced Features
- Added fuzzy matching service for professor names
- Implemented conversation context management
- Added session storage in SQLite
- Improved prompt engineering for better responses
- Added caching to reduce API costs
- Enhanced entity extraction with multiple patterns

### Day 3: Refinement
- Iterated on prompt engineering based on test queries
- Tuned fuzzy matching similarity threshold (0.6)
- Added semester detection and filtering
- Improved context handling for follow-up questions
- Fixed bugs with possessive forms and contractions
- Optimized caching strategy

## Alternatives Considered

### Option 1: OpenAI Function Calling / Structured Output
- **Pros**: More structured extraction, better type safety
- **Cons**: More complex implementation, requires API call for every query
- **Decision**: Used regex + fuzzy matching for extraction, AI only for analysis

### Option 2: Named Entity Recognition (NER) Library
- **Pros**: More sophisticated extraction, handles edge cases
- **Cons**: Additional dependency, may not recognize professor names
- **Decision**: Used regex + fuzzy matching for faster, more targeted extraction

### Option 3: Fine-tuned Model
- **Pros**: Custom behavior, potentially better accuracy
- **Cons**: Requires training data, time-consuming, expensive
- **Decision**: Used GPT-4 with prompt engineering for immediate results

### Option 4: No Caching
- **Pros**: Always fresh responses, simpler implementation
- **Cons**: High API costs, slower responses, rate limit issues
- **Decision**: Implemented caching to reduce costs and improve performance

### Option 5: Vector Database for Semantic Search
- **Pros**: Better semantic understanding, can find similar queries
- **Cons**: Additional infrastructure, overkill for hackathon
- **Decision**: Used fuzzy matching and caching for simpler solution

## Notes
- Had to iterate on regex patterns multiple times to handle edge cases
- Fuzzy matching threshold (0.6) was tuned based on test queries
- Conversation context was crucial for handling follow-up questions
- Prompt engineering required multiple iterations to get accurate responses
- Caching reduced API costs by ~60% during development
- Had to handle edge cases like contractions ("what's" vs "chyn's")
- Future: Consider using OpenAI's function calling for more structured extraction
- Future: May implement semantic search for better query understanding
- Future: Could add user feedback to improve prompt engineering
- Future: Consider fine-tuning model for domain-specific responses

